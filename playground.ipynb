{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(sentences, embeddings, query_embedding, k = 5):\n",
    "    X = np.stack(embeddings)\n",
    "    score_map = zip(sentences, cosine_similarity(X, query_embedding.reshape(1, -1)))\n",
    "    return sorted(score_map, key=lambda v: v[1], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '../masterthesis/data/scidtb.csv'\n",
    "\n",
    "corpus = pd.read_csv(corpus_path, sep='\\t', header=None)\n",
    "\n",
    "sentences = corpus[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 405M/405M [06:03<00:00, 1.11MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Efficient software packages are rarely employed in practice for tuning NLP models because their interoperability with deep learning frameworks such as PyTorch is not optimized.\"\n",
    "\n",
    "query_embedding = model.encode([query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('These systems suffer from poor portability across domains and their benefit for NLP tasks that involve sentence-level processing is limited.',\n",
       "  array([0.8247389], dtype=float32)),\n",
       " ('The informal nature of social media text renders it very difficult to be automatically processed by natural language processing tools.',\n",
       "  array([0.8205497], dtype=float32)),\n",
       " ('This leads to far fewer language model calls, but while LR decoding is more efficient than CKY decoding, it is unable to capture some hierarchical phrase alignments reachable using CKY decoding and suffers from lower translation quality as a result.',\n",
       "  array([0.80016696], dtype=float32))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(sentences, sentence_embeddings, query_embedding, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbert",
   "language": "python",
   "name": "sbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
